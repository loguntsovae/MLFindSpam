"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è —Ä—É—Å—Å–∫–æ—è–∑—ã—á–Ω—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π —Å –æ—Å–Ω–æ–≤–Ω—ã–º –¥–∞—Ç–∞—Å–µ—Ç–æ–º.

–≠—Ç–æ—Ç –º–æ–¥—É–ª—å –æ–±—ä–µ–¥–∏–Ω—è–µ—Ç —Ñ–∞–π–ª russian_messages.csv —Å –æ—Å–Ω–æ–≤–Ω—ã–º raw.csv,
—Å–æ–∑–¥–∞–≤–∞—è —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –º–Ω–æ–≥–æ—è–∑—ã—á–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏.
"""

import pandas as pd
import os
from pathlib import Path


def merge_datasets():
    """
    –û–±—ä–µ–¥–∏–Ω—è–µ—Ç —Ä—É—Å—Å–∫–æ—è–∑—ã—á–Ω—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è —Å –æ—Å–Ω–æ–≤–Ω—ã–º –¥–∞—Ç–∞—Å–µ—Ç–æ–º.
    
    Returns:
        pd.DataFrame: –û–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç
    """
    # –ü—É—Ç–∏ –∫ —Ñ–∞–π–ª–∞–º
    data_dir = Path(__file__).parent.parent / "data"
    raw_file = data_dir / "raw.csv"
    russian_file = data_dir / "russian_messages.csv"
    output_file = data_dir / "raw_multilingual.csv"
    
    print("üìÇ –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö...")
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ –æ—Å–Ω–æ–≤–Ω–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞ (–∞–Ω–≥–ª–∏–π—Å–∫–∏–π)
    df_english = pd.read_csv(raw_file, encoding='latin-1')
    print(f"‚úì –ó–∞–≥—Ä—É–∂–µ–Ω–æ –∞–Ω–≥–ª–∏–π—Å–∫–∏—Ö —Å–æ–æ–±—â–µ–Ω–∏–π: {len(df_english)}")
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ —Ä—É—Å—Å–∫–æ—è–∑—ã—á–Ω—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π
    df_russian = pd.read_csv(russian_file, encoding='utf-8')
    print(f"‚úì –ó–∞–≥—Ä—É–∂–µ–Ω–æ —Ä—É—Å—Å–∫–∏—Ö —Å–æ–æ–±—â–µ–Ω–∏–π: {len(df_russian)}")
    
    # –û—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –∫–æ–ª–æ–Ω–∫–∏
    df_english = df_english[['v1', 'v2']].copy()
    df_russian = df_russian[['v1', 'v2']].copy()
    
    # –ü–µ—Ä–µ–∏–º–µ–Ω–æ–≤—ã–≤–∞–µ–º –∫–æ–ª–æ–Ω–∫–∏ –¥–ª—è —É–¥–æ–±—Å—Ç–≤–∞
    df_english.columns = ['label', 'message']
    df_russian.columns = ['label', 'message']
    
    # –î–æ–±–∞–≤–ª—è–µ–º –º–µ—Ç–∫—É —è–∑—ã–∫–∞
    df_english['language'] = 'en'
    df_russian['language'] = 'ru'
    
    # –û–±—ä–µ–¥–∏–Ω—è–µ–º –¥–∞—Ç–∞—Å–µ—Ç—ã
    df_combined = pd.concat([df_english, df_russian], ignore_index=True)
    
    # –ü–µ—Ä–µ–º–µ—à–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ
    df_combined = df_combined.sample(frac=1, random_state=42).reset_index(drop=True)
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
    df_combined.to_csv(output_file, index=False, encoding='utf-8')
    print(f"\n‚úì –û–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {output_file}")
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    print("\nüìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞:")
    print(f"   –í—Å–µ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏–π: {len(df_combined)}")
    print(f"   –°–ø–∞–º: {len(df_combined[df_combined['label'] == 'spam'])} ({len(df_combined[df_combined['label'] == 'spam'])/len(df_combined)*100:.1f}%)")
    print(f"   Ham: {len(df_combined[df_combined['label'] == 'ham'])} ({len(df_combined[df_combined['label'] == 'ham'])/len(df_combined)*100:.1f}%)")
    print(f"\n   –ü–æ —è–∑—ã–∫–∞–º:")
    print(f"   –ê–Ω–≥–ª–∏–π—Å–∫–∏–π: {len(df_combined[df_combined['language'] == 'en'])}")
    print(f"   –†—É—Å—Å–∫–∏–π: {len(df_combined[df_combined['language'] == 'ru'])}")
    
    return df_combined


def create_backup():
    """–°–æ–∑–¥–∞–µ—Ç —Ä–µ–∑–µ—Ä–≤–Ω—É—é –∫–æ–ø–∏—é –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–≥–æ raw.csv"""
    data_dir = Path(__file__).parent.parent / "data"
    raw_file = data_dir / "raw.csv"
    backup_file = data_dir / "raw_english_only.csv"
    
    if not backup_file.exists():
        df = pd.read_csv(raw_file, encoding='latin-1')
        df.to_csv(backup_file, index=False, encoding='latin-1')
        print(f"‚úì –°–æ–∑–¥–∞–Ω–∞ —Ä–µ–∑–µ—Ä–≤–Ω–∞—è –∫–æ–ø–∏—è: {backup_file}")


def update_raw_file():
    """
    –û–±–Ω–æ–≤–ª—è–µ—Ç raw.csv –º–Ω–æ–≥–æ—è–∑—ã—á–Ω—ã–º –¥–∞—Ç–∞—Å–µ—Ç–æ–º.
    
    –í–ù–ò–ú–ê–ù–ò–ï: –≠—Ç–æ –∑–∞–º–µ–Ω–∏—Ç –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π raw.csv!
    """
    data_dir = Path(__file__).parent.parent / "data"
    multilingual_file = data_dir / "raw_multilingual.csv"
    raw_file = data_dir / "raw.csv"
    
    if multilingual_file.exists():
        # –ß–∏—Ç–∞–µ–º –º–Ω–æ–≥–æ—è–∑—ã—á–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç
        df = pd.read_csv(multilingual_file, encoding='utf-8')
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ —Ñ–æ—Ä–º–∞—Ç –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–≥–æ raw.csv
        df_output = pd.DataFrame()
        df_output['v1'] = df['label']
        df_output['v2'] = df['message']
        df_output['v3'] = ''
        df_output['v4'] = ''
        df_output['v5'] = ''
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º
        df_output.to_csv(raw_file, index=False, encoding='utf-8')
        print(f"‚úì –§–∞–π–ª {raw_file} –æ–±–Ω–æ–≤–ª–µ–Ω –º–Ω–æ–≥–æ—è–∑—ã—á–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏")
    else:
        print(f"‚úó –§–∞–π–ª {multilingual_file} –Ω–µ –Ω–∞–π–¥–µ–Ω. –°–Ω–∞—á–∞–ª–∞ –≤—ã–ø–æ–ª–Ω–∏—Ç–µ merge_datasets()")


if __name__ == "__main__":
    import sys
    
    print("=" * 60)
    print("üîÑ –û–ë–™–ï–î–ò–ù–ï–ù–ò–ï –î–ê–¢–ê–°–ï–¢–û–í")
    print("=" * 60)
    
    # –°–æ–∑–¥–∞–µ–º —Ä–µ–∑–µ—Ä–≤–Ω—É—é –∫–æ–ø–∏—é
    create_backup()
    
    # –û–±—ä–µ–¥–∏–Ω—è–µ–º –¥–∞—Ç–∞—Å–µ—Ç—ã
    df = merge_datasets()
    
    print("\n" + "=" * 60)
    print("‚ùì –•–æ—Ç–∏—Ç–µ –∑–∞–º–µ–Ω–∏—Ç—å raw.csv –º–Ω–æ–≥–æ—è–∑—ã—á–Ω–æ–π –≤–µ—Ä—Å–∏–µ–π?")
    print("   –≠—Ç–æ –ø–æ–∑–≤–æ–ª–∏—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Ä—É—Å—Å–∫–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è –≤ –æ–±—É—á–µ–Ω–∏–∏.")
    print("   (–û—Ä–∏–≥–∏–Ω–∞–ª —Å–æ—Ö—Ä–∞–Ω–µ–Ω –∫–∞–∫ raw_english_only.csv)")
    print("=" * 60)
    
    if len(sys.argv) > 1 and sys.argv[1] == '--update-raw':
        update_raw_file()
        print("\n‚úÖ –ì–æ—Ç–æ–≤–æ! –¢–µ–ø–µ—Ä—å –º–æ–∂–Ω–æ –∑–∞–ø—É—Å—Ç–∏—Ç—å prepare.py –∏ train.py")
    else:
        print("\n–î–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è raw.csv –∑–∞–ø—É—Å—Ç–∏—Ç–µ:")
        print("  python src/merge_russian_data.py --update-raw")
